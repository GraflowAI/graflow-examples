{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Simple ETL - Graflow Minimal Example\n\nA minimal Extract → Transform → Load workflow."
  },
  {
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GraflowAI/graflow-examples/blob/main/examples/notebooks/simple_etl.ipynb)",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Prerequisites\n\nInstall Graflow and import the core modules:\n- **`@task`** — Decorator to define a workflow task\n- **`workflow`** — Context manager to build and execute a task graph\n- **`TaskExecutionContext`** — Provides access to the shared channel for inter-task communication"
  },
  {
   "cell_type": "code",
   "source": "!pip install graflow",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "from graflow.core.context import TaskExecutionContext\nfrom graflow.core.decorators import task\nfrom graflow.core.workflow import workflow",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Task Definitions\n\nDefine three tasks that form a sequential pipeline using `>>` (the sequential composition operator):\n\n```\nextract >> transform >> load\n```\n\nEach task uses `inject_context=True` to access the shared **channel** — a key-value store for passing data between tasks."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@task(inject_context=True)\ndef extract(ctx: TaskExecutionContext):\n    \"\"\"Load raw data.\"\"\"\n    raw_data = [\n        {\"name\": \"Alice\", \"score\": 85},\n        {\"name\": \"Bob\", \"score\": 42},\n        {\"name\": \"Charlie\", \"score\": 73},\n        {\"name\": \"Diana\", \"score\": 91},\n    ]\n    print(f\"[Extract] {len(raw_data)} records loaded\")\n    ctx.get_channel().set(\"raw_data\", raw_data)\n\n\n@task(inject_context=True)\ndef transform(ctx: TaskExecutionContext):\n    \"\"\"Filter records with score >= 50 and assign a grade.\"\"\"\n    channel = ctx.get_channel()\n    raw = channel.get(\"raw_data\")\n\n    results = []\n    for r in raw:\n        if r[\"score\"] >= 50:\n            grade = \"A\" if r[\"score\"] >= 90 else \"B\" if r[\"score\"] >= 70 else \"C\"\n            results.append({**r, \"grade\": grade})\n\n    print(f\"[Transform] {len(raw)} -> {len(results)} records\")\n    channel.set(\"transformed\", results)\n\n\n@task(inject_context=True)\ndef load(ctx: TaskExecutionContext):\n    \"\"\"Output the results.\"\"\"\n    data = ctx.get_channel().get(\"transformed\")\n    print(\"[Load] Results:\")\n    for r in data:\n        print(f\"  {r['name']}: {r['score']} ({r['grade']})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Run Workflow\n\nUse the `workflow()` context manager to register the task graph and execute it. The `>>` operator wires tasks sequentially, and `wf.execute()` starts execution from the given entry task."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with workflow(\"hello_etl\") as wf:\n",
    "    extract >> transform >> load\n",
    "    wf.execute(\"extract\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}