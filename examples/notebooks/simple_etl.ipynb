{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple ETL - Graflow Minimal Example\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GraflowAI/graflow-examples/blob/main/examples/notebooks/simple_etl.ipynb)\n",
    "\n",
    "A minimal Extract → Transform → Load workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Install Graflow and import the core modules:\n",
    "- **`@task`** — Decorator to define a workflow task\n",
    "- **`workflow`** — Context manager to build and execute a task graph\n",
    "- **`TaskExecutionContext`** — Provides access to the shared channel for inter-task communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get -qq install -y libgraphviz-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U graflow[visualization]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graflow.core.context import TaskExecutionContext\n",
    "from graflow.core.decorators import task\n",
    "from graflow.core.workflow import workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Definitions\n",
    "\n",
    "Define four tasks with parallel transforms using `>>` (sequential) and `|` (parallel) operators:\n",
    "\n",
    "```\n",
    "extract >> (filter_pass | assign_grade) >> load\n",
    "```\n",
    "\n",
    "Each task uses `inject_context=True` to access the shared **channel** — a key-value store for passing data between tasks. The two transform tasks run concurrently and both write their results to the channel before `load` collects them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(inject_context=True)\n",
    "def extract(ctx: TaskExecutionContext):\n",
    "    \"\"\"Load raw data.\"\"\"\n",
    "    raw_data = [\n",
    "        {\"name\": \"Alice\", \"score\": 85},\n",
    "        {\"name\": \"Bob\", \"score\": 42},\n",
    "        {\"name\": \"Charlie\", \"score\": 73},\n",
    "        {\"name\": \"Diana\", \"score\": 91},\n",
    "    ]\n",
    "    print(f\"[Extract] {len(raw_data)} records loaded\")\n",
    "    ctx.get_channel().set(\"raw_data\", raw_data)\n",
    "\n",
    "\n",
    "@task(inject_context=True)\n",
    "def filter_pass(ctx: TaskExecutionContext):\n",
    "    \"\"\"Filter records with score >= 50.\"\"\"\n",
    "    channel = ctx.get_channel()\n",
    "    raw = channel.get(\"raw_data\")\n",
    "    passed = [r for r in raw if r[\"score\"] >= 50]\n",
    "    print(f\"[Filter] {len(raw)} -> {len(passed)} records passed\")\n",
    "    channel.set(\"passed\", passed)\n",
    "\n",
    "\n",
    "@task(inject_context=True)\n",
    "def assign_grade(ctx: TaskExecutionContext):\n",
    "    \"\"\"Assign a grade to each record.\"\"\"\n",
    "    channel = ctx.get_channel()\n",
    "    raw = channel.get(\"raw_data\")\n",
    "    graded = []\n",
    "    for r in raw:\n",
    "        grade = \"A\" if r[\"score\"] >= 90 else \"B\" if r[\"score\"] >= 70 else \"C\" if r[\"score\"] >= 50 else \"F\"\n",
    "        graded.append({**r, \"grade\": grade})\n",
    "    print(f\"[Grade] {len(graded)} records graded\")\n",
    "    channel.set(\"graded\", graded)\n",
    "\n",
    "\n",
    "@task(inject_context=True)\n",
    "def load(ctx: TaskExecutionContext):\n",
    "    \"\"\"Merge and output the results.\"\"\"\n",
    "    channel = ctx.get_channel()\n",
    "    passed = {r[\"name\"] for r in channel.get(\"passed\")}\n",
    "    graded = channel.get(\"graded\")\n",
    "    results = [r for r in graded if r[\"name\"] in passed]\n",
    "    print(\"[Load] Results:\")\n",
    "    for r in results:\n",
    "        print(f\"  {r['name']}: {r['score']} ({r['grade']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Workflow\n",
    "\n",
    "Use the `workflow()` context manager to register the task graph and execute it. The `>>` operator wires tasks sequentially, `|` runs tasks in parallel, and `wf.execute()` starts execution from the entry task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with workflow(\"hello_etl\") as wf:\n",
    "    _ = extract >> (filter_pass | assign_grade).set_group_name(\"transforms\") >> load\n",
    "    wf.execute(\"extract\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "`print(wf.graph)` renders an ASCII diagram via `TaskGraph.__str__`. `draw_mermaid_png` renders the graph as a PNG image via the Mermaid.INK API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Task Graph (ASCII):\")\n",
    "print(\"-\" * 70)\n",
    "print(wf.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "from graflow.utils.graph import draw_mermaid_png\n",
    "\n",
    "png_bytes = draw_mermaid_png(wf.graph.nx_graph(), title=\"Simple ETL Pipeline\")\n",
    "display(Image(png_bytes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graflow-examples (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
